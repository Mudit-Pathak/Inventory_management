{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" from google.colab import drive\ndrive.mount('/content/drive')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\nsales = pd.read_csv(\"/content/drive/MyDrive/ML project/SalesFINAL12312016.csv\", parse_dates=[\"SalesDate\"])\npurchase = pd.read_csv(\"/content/drive/MyDrive/ML project/PurchasesFINAL12312016.csv\")\ninvoice = pd.read_csv(\"/content/drive/MyDrive/ML project/InvoicePurchases12312016.csv\")\nend_inv = pd.read_csv(\"/content/drive/MyDrive/ML project/EndInvFINAL12312016.csv\")\nbeg_inv = pd.read_csv(\"/content/drive/MyDrive/ML project/BegInvFINAL12312016.csv\")\npurchase_price = pd.read_csv(\"/content/drive/MyDrive/ML project/2017PurchasePricesDec.csv\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(beg_inv.head())\ndisplay(end_inv.head())\nnuniques = {\"beg_inv\": beg_inv.nunique(), \"end_inv\": end_inv.nunique()}\ndisplay(\n    pd.DataFrame(nuniques).T[\n        [\n            \"InventoryId\",\n            \"Store\",\n            \"City\",\n            \"Brand\",\n            \"Description\",\n            \"Size\",\n            \"onHand\",\n            \"startDate\",\n            \"endDate\",\n        ]\n    ]\n)\nprint(\n    f\"beg_inv Brand nunique: {beg_inv.Brand.nunique()}, desc + size nunique: {(beg_inv['Description'] + ' ' + beg_inv['Size']).nunique()}??? Might need cleaning\"\n)\nprint(\n    f\"end_inv Brand nunique: {end_inv.Brand.nunique()}, desc + size nunique: {(end_inv['Description'] + ' ' + end_inv['Size']).nunique()}\"\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beg_inv_brand = beg_inv.loc[:]\nbeg_inv_brand[\"Desc_Size\"] = beg_inv_brand[\"Description\"] + \" \" + beg_inv_brand[\"Size\"]\ngroup_desc = (\n    beg_inv_brand[[\"Brand\", \"Desc_Size\"]].groupby(\"Desc_Size\")[\"Brand\"].unique()\n)\ngroup_desc.loc[group_desc.apply(len) > 1]\n\n# ? will assume brand is id for Description + Size\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(sales.head())\ndisplay(\n    beg_inv.loc[\n        (beg_inv[\"Brand\"] == 1004) & (beg_inv[\"InventoryId\"] == \"1_HARDERSFIELD_1004\")\n    ]\n)\n# ? Inventory ID = store_city_brand, Brand = description + Size, With Inventory ID we can find how many onhand the inventory have at the beginning and end.\nprint(sales.Classification.unique())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(purchase.head())\ndisplay(invoice.head())\n# * assume, lead time = Receiving Date - Purchase Order Date. They did not produce their own goods but buy from vendors.\n#  * freight is cargo or shipping cost.\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(purchase_price.head())\npurchase_price_vendor = purchase_price[\"VendorName\"].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.api import SARIMAX\nfrom IPython.display import clear_output\nfrom math import pow\nimport plotly.express as px\n\n# * Group by date, sum sales quantity to get total sales quantity per day\nsales_quantity_price = sales.groupby(\"SalesDate\").agg({\"SalesQuantity\": \"sum\"})\n\n# * Load ARIMA, Autoregressive Moving Average\nmod = SARIMAX(sales_quantity_price, order=(5, 1, 1), trend=\"c\")\nres = mod.fit()\n\n# * Add more dates to sales_quantity_price, predict until 2016-03-31\nfor i in pd.date_range(\"2016-03-01\", \"2016-03-31\", freq=\"D\"):\n    sales_quantity_price.loc[i, \"SalesQuantity\"] = None\nsales_quantity_price[\"forecast\"] = res.predict(1, 60)\n\n# * Plot with x-axis limited to January and February\nclear_output()\nfig = px.line(sales_quantity_price, x=sales_quantity_price.index, y=[\"SalesQuantity\", \"forecast\"])\nfig.update_xaxes(range=[\"2016-01-01\", \"2016-02-29\"])  # Limiting the x-axis to January and February\nfig.show()\n\n# * Calculate MAPE error\nabsolute_diff = abs(sales_quantity_price[\"SalesQuantity\"] - sales_quantity_price[\"forecast\"])\nrelative_diff = absolute_diff / sales_quantity_price[\"SalesQuantity\"] * 100\nprint(\"\\nMAPE:\", relative_diff.dropna().mean())\n\n# * Calculate R2\n# Calculate the mean of actual values\nmean_actual = sales_quantity_price[\"SalesQuantity\"].mean()\n\n# Calculate the total sum of squares (SST)\nsst = ((sales_quantity_price[\"SalesQuantity\"] - mean_actual) ** 2).sum()\n\n# Calculate the residual sum of squares (SSR)\nssr = ((sales_quantity_price[\"SalesQuantity\"] - sales_quantity_price[\"forecast\"]) ** 2).sum()\n\n# Calculate R^2\nr2 = 1 - (ssr / sst)\nprint(f'R^2: {r2}')\n\n# Print top 3 highest relative differences\nprint(relative_diff.sort_values(ascending=False).head(3))\n\n# Calculate and print forecast total demand for March\nprint(\"March Forecast Total Demand: \", sales_quantity_price.loc[\"2016-03-01\":\"2016-03-31\", \"forecast\"].sum())\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.deterministic import DeterministicProcess, CalendarFourier\nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd\n\n# Assuming 'sales' is your DataFrame\nsales_quantity_price = sales.groupby(\"SalesDate\").agg({\"SalesQuantity\": \"sum\"})\nsales_quantity_price.index = pd.to_datetime(sales_quantity_price.index)\nsales_quantity_price['week'] = sales_quantity_price.index.month\nsales_quantity_price['day'] = sales_quantity_price.index.dayofweek\n\n# Correcting the frequency to 'M' for month end\nfourierM = CalendarFourier(freq=\"M\", order=6)\n\ndp = DeterministicProcess(\n    index=sales_quantity_price.index,\n    constant=True,\n    order=4,\n    seasonal=True,\n    additional_terms=[fourierM],\n)\n\nX = dp.in_sample()\nmodel = LinearRegression().fit(X, sales_quantity_price['SalesQuantity'])\ny_pred = pd.Series(\n    model.predict(X),\n    index=X.index,\n    name=\"fitted\"\n)\n\n# Filter for positive forecast values\nsales_quantity_price[\"forecast\"] = y_pred\nfiltered_sales_quantity_price = sales_quantity_price[sales_quantity_price[\"forecast\"] > 0]\n\n# Plotting only positive forecasts\nfiltered_sales_quantity_price[[\"SalesQuantity\", \"forecast\"]].plot()\n\n# * calculate MAPE error for positive forecasts only\nabsolute_diff = abs(filtered_sales_quantity_price[\"SalesQuantity\"] - filtered_sales_quantity_price[\"forecast\"])\nrelative_diff = absolute_diff / filtered_sales_quantity_price[\"SalesQuantity\"] * 100\nprint(\"\\nMAPE:\", relative_diff.dropna().mean())\n\n# * Calculate R2 for positive forecasts only\n# Calculate the mean of actual values\nmean_actual = filtered_sales_quantity_price[\"SalesQuantity\"].mean()\n\n# Calculate the total sum of squares (SST)\nsst = ((filtered_sales_quantity_price[\"SalesQuantity\"] - mean_actual) ** 2).sum()\n\n# Calculate the residual sum of squares (SSR)\nssr = ((filtered_sales_quantity_price[\"SalesQuantity\"] - filtered_sales_quantity_price[\"forecast\"]) ** 2).sum()\n\n# Calculate R^2\nr2 = 1 - (ssr / sst)\nprint(f'R^2: {r2}')\n\n# Print top 3 highest relative differences\nprint(relative_diff.sort_values(ascending=False).head(3))\n\n# Calculate and print forecast total demand for March\nmarch_forecast_total_demand = filtered_sales_quantity_price.loc[\"2016-03-01\":\"2016-03-31\", \"forecast\"].sum()\nprint(\"March Forecast Total Demand: \", march_forecast_total_demand)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  ABC = (\n    sales.groupby(\"Brand\")\n    .agg({\"SalesQuantity\": \"sum\"})\n    .sort_values(\"SalesQuantity\", ascending=False)\n)\ndisplay(\n    \"Top 5 Demand\",\n    ABC.head(),\n    \"Bottom 5 Demand\",\n    ABC.tail(),\n    \"describe data\",\n    ABC.describe().T,\n)\nbins = [0, 100, 1000, 30000]\nlabels = [\"C: <100\", \"B: 100-1k\", \"A: 1k-30k\"]\nABC['bin'] = pd.cut(ABC[\"SalesQuantity\"], bins, labels=labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar(ABC['bin'].value_counts().index, ABC['bin'].value_counts().values, color=['blue','green','red'])\nfor i, value in enumerate(ABC['bin'].value_counts().values):\n    plt.text(i, value, str(value), ha='center', va='bottom')\nplt.title('Histogram of ABC analysis, total unique brand from group A to C')\nplt.xlabel('Group')\nplt.ylabel('Frequency')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_group = ABC.groupby('bin').agg({\"SalesQuantity\":'sum'})['SalesQuantity']\ntotal = px.histogram(total_group.value_counts(), x=total_group.index, y=total_group.values, color=total_group.index, title=\"ABC analysis, total sales of brand from group A to C\",text_auto=True)\ntotal.update_layout(\n  width=800,\n  height=600,\n    xaxis_title='Group',\n    yaxis_title='Total_sales',\n    bargap=0.1,  # Gap between bars\n)\ntotal.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# * Demand 2 month\nfrom math import pow, ceil\n\n\ndemand_jan_feb = (\n\n    sales.groupby(\"Brand\")\n\n    .agg({\"SalesQuantity\": \"sum\"})\n\n    .sort_values(\"SalesQuantity\", ascending=False)\n)\n\n\n# * Cost Per Order (CPO), Freight Cost\n\npurchase_invoice = pd.merge(\n    left=purchase[[\"PONumber\", \"Brand\", \"Description\", \"Size\", \"Quantity\"]],\n    right=invoice,\n    on=\"PONumber\",\n    how=\"right\",\n)\n\npurchase_invoice_vol = pd.merge(\n    left=purchase_invoice,\n    right=purchase_price[[\"Brand\", \"Volume\"]],\n    on=\"Brand\",\n    how=\"left\",\n)\npurchase_invoice_vol[\"vol_quantity\"] = purchase_invoice_vol[\"Quantity_x\"].astype(\n    \"float\"\n) * purchase_invoice_vol[\"Volume\"].astype(\"float\")\npurchase_invoice_vol.set_index(\"PONumber\", inplace=True)\npurchase_invoice_vol[\"vol_quantity_total\"] = purchase_invoice_vol.groupby(\n    \"PONumber\"\n).agg({\"vol_quantity\": \"sum\"})\npurchase_invoice_vol[\"CPO\"] = (\n    purchase_invoice_vol[\"vol_quantity\"]\n    / purchase_invoice_vol[\"vol_quantity_total\"]\n    * purchase_invoice_vol[\"Freight\"]\n)\n# **************************************\nCPO = purchase_invoice_vol.groupby(\"Brand\").agg({\"CPO\": \"mean\"})\n#****************************************\n# * Cost Per Unit (C), Holding Cost (%) assume holding cost = 30%, Holding Cost ($) = I*C = I*0.3\nC = purchase_price[[\"Brand\", \"PurchasePrice\"]].set_index(\"Brand\")\nH = C * 0.3\n\n# * Combine to Brand\nEOQ = demand_jan_feb.copy()\nEOQ[\"CPO\"] = CPO\nEOQ[\"H\"] = H\n\n# * Calculate and dropna\nEOQ[\"EOQ\"] = 2 * EOQ[\"SalesQuantity\"] * EOQ[\"CPO\"] / EOQ[\"H\"]\nEOQ[\"EOQ\"] = EOQ[\"EOQ\"].apply(lambda x: ceil(pow(x, 0.5)) if pd.notna(x) else 0)\nEOQ.dropna(inplace=True)\nEOQ[\"Volume\"] = purchase_price[[\"Brand\", \"Volume\"]].set_index(\"Brand\")\nEOQ['ABC']=ABC['bin']\ndisplay(EOQ.head(15), EOQ.describe(),EOQ.groupby(\"ABC\").agg({\"EOQ\":\"mean\"}).T)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# * Average Daily Unit Sales\nsales_velocity = (\n    sales.groupby([\"Brand\", \"Description\"]).agg({\"SalesQuantity\": \"sum\"}).reset_index()\n)\ndays = (\n    pd.to_datetime(sales[\"SalesDate\"]).max() - pd.to_datetime(sales[\"SalesDate\"]).min()\n).days\nsales_velocity[\"mean_daily_sales\"] = sales_velocity[\"SalesQuantity\"] / days\nmean_daily_sales = sales_velocity.set_index(\"Brand\")[\"mean_daily_sales\"]\ndisplay(mean_daily_sales.to_frame().T, mean_daily_sales.describe().to_frame().T)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# * Average Lead Time\npurchase[\"lead_time\"] = (\n    pd.to_datetime(purchase[\"ReceivingDate\"]) - pd.to_datetime(purchase[\"PODate\"])\n).dt.days\nlead_time_brand = purchase.groupby(\"Brand\").agg({\"lead_time\": \"mean\"})\ndisplay(lead_time_brand.T, lead_time_brand.describe().T)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# * Safety Stock\nmax_sales_brand = sales.groupby(\"Brand\").agg({\"SalesQuantity\": \"max\"})\nsafety_stock = (\n    max_sales_brand[\"SalesQuantity\"]\n    - sales_velocity.set_index(\"Brand\")[\"mean_daily_sales\"]\n)\ndisplay(safety_stock.to_frame().T, safety_stock.describe().to_frame().T)\n# * notice there are negatives to fix this problem we will just set them to 0\nsafety_stock[safety_stock < 0] = 0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# * Reorder Point Analysis\nRPA = (lead_time_brand['lead_time'] * mean_daily_sales) + safety_stock\nRPA.name = \"ReorderPoint\"\nRPA.dropna(inplace=True)\nRPA = RPA.apply(lambda x: ceil(x)).to_frame()\nRPA['ABC'] = ABC['bin']\ndisplay(RPA.T,RPA.describe().T)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(\n    RPA, x=\"ReorderPoint\", color=\"ABC\", nbins=50, title=\"Reorder Point Analysis distribution\", log_y=True\n)\nfig.update_layout(\n    bargap=0.2,\n    xaxis_title_text=\"ReorderPointBin\",  # xaxis label\n    yaxis_title_text=\"total_count_brand\",  # yaxis label\n\n)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(lead_time_brand, x='lead_time', nbins=50, title=\"Lead Time Analysis distribution\",text_auto=True)\nfig.update_layout(\n    bargap=0.1,\n    xaxis_title_text=\"average_lead_time\",  # xaxis label\n    yaxis_title_text=\"total_count_brand\",  # yaxis label\n    height=600\n)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nannual_inventory_value = end_inv.copy()\nannual_inventory_value[\"total_value\"] = (\n    annual_inventory_value[\"onHand\"] * annual_inventory_value[\"Price\"]\n)\nbrand_inventory_value = annual_inventory_value.groupby(\"Brand\").agg(\n    {\"Price\": \"first\", \"Description\": \"first\", \"total_value\": \"sum\", \"onHand\": \"sum\"}\n)\n\nbrand_inventory_value.sort_values(\"total_value\", ascending=False, inplace=True)\nbrand_inventory_value[\"RPA\"] = RPA[\"ReorderPoint\"]\nbrand_inventory_value[\"total_value_if_RPA\"] = (\n    brand_inventory_value[\"RPA\"] * brand_inventory_value[\"Price\"]\n)\nbrand_inventory_value[\"total_value_saved_if_RPA\"] = (\n    brand_inventory_value[\"total_value\"] - brand_inventory_value[\"total_value_if_RPA\"]\n)\nbrand_inventory_value.dropna(inplace=True)\n\nfig = go.Figure()\nfig.add_trace(\n    go.Histogram(\n        x=brand_inventory_value[\"total_value\"],\n        name=\"end of year inventory\",\n        nbinsx=50,\n    )\n)\nfig.add_trace(\n    go.Histogram(\n        x=brand_inventory_value[\"total_value_if_RPA\"],\n        name=\"if follow reorder point/optimal level\",\n        nbinsx=50,\n    )\n)\nfig.update_yaxes(type=\"log\")\nfig.update_layout(\n    title_text=\"Total Inventory Value Distribution\",\n    xaxis_title_text=\"total inventory value\",  # xaxis label\n    yaxis_title_text=\"total number of brands\",  # yaxis label\n    bargap=0.2,  # gap between bars of adjacent location coordinates\n    bargroupgap=0.1,  # gap between bars of the same location coordinates\n)\n\nfig.show()\n\ndisplay(brand_inventory_value[['total_value','total_value_if_RPA','total_value_saved_if_RPA']].sum().apply(lambda x: f\"${x:,.0f}\").to_frame().T)\nbrand_inventory_value[\"total_value\"] = brand_inventory_value[\"total_value\"].apply(\n    lambda x: f\"${x:,.0f}\"\n)\nbrand_inventory_value[\"total_value_if_RPA\"] = brand_inventory_value[\n    \"total_value_if_RPA\"\n].apply(lambda x: f\"${x:,.0f}\")\nbrand_inventory_value[\"total_value_saved_if_RPA\"] = brand_inventory_value[\n    \"total_value_saved_if_RPA\"\n].apply(lambda x: f\"${x:,.0f}\")\ndisplay(brand_inventory_value.head(10), brand_inventory_value.tail(10))\n","metadata":{},"execution_count":null,"outputs":[]}]}